{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSS: Expansión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.summarization import keywords\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import googletrans\n",
    "import datetime\n",
    "from termcolor import colored\n",
    "from IPython.display import display, Markdown, Latex, HTML\n",
    "import re\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_only_text(url):\n",
    "    \n",
    "    \"\"\"\n",
    "    return the title and the text of the article at the \n",
    "    specified url\n",
    "    \"\"\"\n",
    "    \n",
    "    page=urlopen(url)\n",
    "    soup=BeautifulSoup(page,\"html.parser\")\n",
    "    text=' '.join(map(lambda p: p.text, soup.find_all('p')))\n",
    "    # Eliminar Última Hora\n",
    "    rest = soup.find_all('p', attrs={'class' : \"line-clamp_x2 ue-c-widget__article-headline\"})[0].text\n",
    "    index = text.find(rest)\n",
    "    final_text = text[:index]\n",
    "    return [final_text,soup.title.text]\n",
    "\n",
    "def find_between( s, first, last ):\n",
    "    try:\n",
    "        start = s.index( first ) + len( first )\n",
    "        end = s.index( last, start )\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expansion_news(expansion_entries,word_count=100):\n",
    "    expansion = {}\n",
    "    for i in range(len(expansion_entries)):\n",
    "        noticia = {'newspaper':None,'title':None,'headline':None,'summarise':None,'date':None,\n",
    "                   'link':None,'text':None,'img':None}\n",
    "        # Periodico\n",
    "        noticia['newspaper'] = find_between(s=expansion_entries[i]['id'], first='www.', last='.' )\n",
    "        # Title\n",
    "        noticia['title'] = expansion_entries[i]['title']\n",
    "        # Headline\n",
    "        index = expansion_entries[i]['summary_detail']['value'].find('&nbsp')\n",
    "        if index != -1:\n",
    "            noticia['headline'] = expansion_entries[i]['summary_detail']['value'][:index]\n",
    "        else:\n",
    "            noticia['headline'] = re.sub(pattern='&quot;',repl='\"',string=expansion_entries[i]['summary_detail']['value'])\n",
    "        # Date\n",
    "        noticia['date'] = {'date1':expansion_entries[i]['published'],'date2':expansion_entries[i]['published_parsed']}\n",
    "        # Link\n",
    "        noticia['link'] = expansion_entries[i]['id']\n",
    "        # Text\n",
    "        text = get_only_text(expansion_entries[i]['id'])[0]\n",
    "        noticia['text'] = text\n",
    "        # Summarise\n",
    "        if text.find('Para seguir leyendo') == -1:\n",
    "            noticia['summarise'] = summarize(text, word_count=word_count)\n",
    "        else:\n",
    "            noticia['summarise'] = 'Premium Content'\n",
    "        # Image\n",
    "        noticia['img'] = expansion_entries[i]['media_content'][0]['url']\n",
    "        expansion.update({'Noticia'+'_'+str(\"%02d\")%(i+1):noticia})\n",
    "    return expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RSS Expansión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Entradas Expansión: 35\n"
     ]
    }
   ],
   "source": [
    "url_expansion = 'https://e00-expansion.uecdn.es/rss/empresasbanca.xml'\n",
    "expansion = feedparser.parse(url_expansion)\n",
    "expansion_entries = expansion['entries']\n",
    "\n",
    "print('Total Entradas Expansión:',len(expansion_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b068003f4f3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mexpansion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpansion_news\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpansion_entries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-231d4838c3f0>\u001b[0m in \u001b[0;36mexpansion_news\u001b[1;34m(expansion_entries, word_count)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mnoticia\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'link'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpansion_entries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# Text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_only_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpansion_entries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mnoticia\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# Summarise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-8067c7bd8d6e>\u001b[0m in \u001b[0;36mget_only_text\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Eliminar Última Hora\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mrest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m\"line-clamp_x2 ue-c-widget__article-headline\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mfinal_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "expansion = expansion_news(expansion_entries,word_count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday = datetime.datetime.today() - datetime.timedelta(days=1)\n",
    "before_yes = datetime.datetime.today() - datetime.timedelta(days=2)\n",
    "\n",
    "for i in list(expansion.keys()):\n",
    "    if expansion[i]['date']['date2'][2] in [datetime.datetime.today().day,yesterday.day,before_yes.day]:\n",
    "        print(colored((expansion[i]['newspaper']).upper(),'green',attrs=['bold']))\n",
    "        print(colored(expansion[i]['date']['date1'],'grey',attrs=['bold']))\n",
    "        print(colored(expansion[i]['title'],'magenta',attrs=['bold']))\n",
    "        print(colored('Headline','blue'))\n",
    "        print(expansion[i]['headline'])\n",
    "        print(colored('Summarise','blue'))\n",
    "        \n",
    "        if expansion[i]['summarise'] != 'Premium Content':\n",
    "            print(expansion[i]['summarise'])\n",
    "        else:\n",
    "            print(colored(expansion[i]['summarise'],'red'))\n",
    "        print(colored('Text','blue'))\n",
    "        print(expansion[i]['text'])\n",
    "        url = expansion[i]['img']\n",
    "        display(Image(url=url,width=500))\n",
    "        display(Markdown('<a href=\"'+expansion[i]['link']+'\">Link</a>'))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
