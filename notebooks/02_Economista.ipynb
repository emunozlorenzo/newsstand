{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSS: Economista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.summarization import keywords\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import datetime\n",
    "from termcolor import colored\n",
    "from IPython.display import display, Markdown, Latex, HTML\n",
    "import re\n",
    "from IPython.display import Image\n",
    "import urllib\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_only_text1(url):\n",
    "    \n",
    "    \"\"\"\n",
    "    return the title and the text of the article at the \n",
    "    specified url\n",
    "    \"\"\"\n",
    "    \n",
    "    page=urlopen(url)\n",
    "    soup=BeautifulSoup(page,\"html.parser\")\n",
    "    text=' '.join(map(lambda p: p.text, soup.find_all('p')))\n",
    "    # Eliminar Ãšltima Hora\n",
    "    rest = soup.find_all('p', attrs={'class' : \"line-clamp_x2 ue-c-widget__article-headline\"})[0].text\n",
    "    index = text.find(rest)\n",
    "    final_text = text[:index]\n",
    "    return [final_text,soup.title.text]\n",
    "\n",
    "def get_only_text(url):\n",
    "    \n",
    "    \"\"\"\n",
    "    return the title and the text of the article at the \n",
    "    specified url\n",
    "    \"\"\"\n",
    "    \n",
    "    page=urlopen(url)\n",
    "    soup=BeautifulSoup(page,\"html.parser\")\n",
    "    text=' '.join(map(lambda p: p.text, soup.find_all('p')))\n",
    "    return [text,soup.title.text]\n",
    "\n",
    "def get_img(url):\n",
    "    page=urlopen(url)\n",
    "    soup=BeautifulSoup(page,\"html.parser\")\n",
    "    if soup.find('div',class_='articleHero') != None:\n",
    "        if soup.find('div',class_='articleHero').find('div',class_='articleImage') != None:\n",
    "            return soup.find('div',class_='articleHero').find('div',class_='articleImage').find('img')['data-src']\n",
    "        else: None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def find_between( s, first, last ):\n",
    "    try:\n",
    "        start = s.index( first ) + len( first )\n",
    "        end = s.index( last, start )\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\"\n",
    "\n",
    "def string_found(string1, string2):\n",
    "    \n",
    "    if re.search(r\"\\b\" + re.escape(string1) + r\"\\b\", string2.lower()):\n",
    "        return True\n",
    "    return False     \n",
    "    \n",
    "def bank_tags(text):\n",
    "    tags = []\n",
    "    dict_banks = {'Santander':['santander'],'BBVA':['bbva'],'Bankinter':['bankinter'],'Bankia':['bankia'],\n",
    "                 'Sabadell':['sabadell'],'ING':['ing'],'Abanca':['abanca'],'Deutsche Bank':['deutsche'],\n",
    "                  'CaixaBank':['caixabank'],'Openbank':['openbank']}\n",
    "    for key,values in dict_banks.items():\n",
    "        for i in values:\n",
    "            if string_found(i,text.lower()):\n",
    "                tags.append(key)\n",
    "                break\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def economista_news(economista_entries,word_count=100):\n",
    "    economista = {}\n",
    "    for i in range(len(economista_entries)):\n",
    "        print(i)\n",
    "        noticia = {'newspaper':None,'title':None,'headline':None,'summarise':None,'date':None,'link':None,\n",
    "                   'text':None,'current_date':None,'img':None,'premium':None,'tag':None}\n",
    "        # Periodico\n",
    "        noticia['newspaper'] = find_between(s=economista_entries[i]['id'], first='www.el', last='.' )\n",
    "        # Title\n",
    "        noticia['title'] = economista_entries[i]['title']\n",
    "        # Headline\n",
    "        headline =  re.sub(pattern='&quot;',repl='\"',string=economista_entries[i]['summary_detail']['value'])\n",
    "        noticia['headline'] = headline\n",
    "        # Date\n",
    "        noticia['date'] = {'date1':economista_entries[i]['published'],'date2':economista_entries[i]['published_parsed']}\n",
    "        # Link\n",
    "        noticia['link'] = economista_entries[i]['id']\n",
    "        # Text\n",
    "        text = get_only_text(economista_entries[i]['id'])[0][len(headline)+1:]\n",
    "        if  text.find('\\n\\t\\t\\t\\tif') != -1:\n",
    "            index =  text.find('\\n\\t\\t\\t\\tif')\n",
    "            text = text[:index]\n",
    "        noticia['text'] = text\n",
    "        # Bank Tags\n",
    "        noticia['tag'] = bank_tags(text)\n",
    "        # Summarise\n",
    "        noticia['summarise'] = summarize(text, word_count=word_count)\n",
    "        # Current Date\n",
    "        noticia['current_date'] = datetime.datetime.now().timetuple()\n",
    "        # Image\n",
    "        noticia['img'] = get_img(economista_entries[i]['id'])\n",
    "    return economista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RSS Economista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Entradas Economista: 12\n"
     ]
    }
   ],
   "source": [
    "url_economista = 'https://www.eleconomista.es/rss/rss-empresas.php'\n",
    "economista = feedparser.parse(url_economista)\n",
    "economista_entries = economista['entries']\n",
    "\n",
    "print('Total Entradas Economista:',len(economista_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "economista = economista_news(economista_entries,word_count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday = datetime.datetime.today() - datetime.timedelta(days=1)\n",
    "before_yes = datetime.datetime.today() - datetime.timedelta(days=2)\n",
    "\n",
    "for i in list(economista.keys()):\n",
    "    if economista[i]['date']['date2'][2] in [datetime.datetime.today().day,yesterday.day,before_yes.day]:\n",
    "        print(colored((economista[i]['newspaper']).upper(),'green',attrs=['bold']))\n",
    "        print(colored(economista[i]['date']['date1'],'grey',attrs=['bold']))\n",
    "        print(colored(economista[i]['title'],'magenta',attrs=['bold']))\n",
    "        print(colored('Headline','blue'))\n",
    "        print(economista[i]['headline'])\n",
    "        print(colored('Summarise','blue'))\n",
    "        \n",
    "        if economista[i]['summarise'] != 'Premium Content':\n",
    "            print(economista[i]['summarise'])\n",
    "        else:\n",
    "            print(colored(economista[i]['summarise'],'red'))\n",
    "        print(colored('Text','blue'))\n",
    "        print(economista[i]['text'])\n",
    "        url = cincod[i]['img']\n",
    "        display(Image(url=url,width=500))\n",
    "        display(Markdown('<a href=\"'+economista[i]['link']+'\">Link</a>'))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
